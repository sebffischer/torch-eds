---
title: "Training Efficiency"
---

{{< include _setup.qmd >}}

**Question 1:** Validation

In this exercise, we will once again train a simple multi-layer perceptron on the *Indian Liver Patient Dataset* (ILPD). Create a learner that:

1. Uses 2 hidden layers with 100 neurons each.
2. Utilizes a batch size of 128.
3. Trains for 200 epochs.
4. Employs a validation set comprising 30% of the data.
5. Tracks the training and validation log-loss during training.
6. Utilizes trace-jitting to speed up the training process.
7. Employs the history callback to record the training and validation log-loss during training.

Afterward, plot the validation log-loss, which is accessible via `learner$model$callbacks$history`.

Below, we create the task and remove the `gender` feature for simplicity.

```{r}
library(mlr3verse)
library(mlr3torch)
ilpd_num <- tsk("ilpd")
ilpd_num$select(setdiff(ilpd_num$feature_names, "gender"))
ilpd_num
```

<details>
<summary>Hint</summary>
* To specify the validation set, use the `validate` field, which can either be set during construction or by calling `$configure()`.
* Trace-jitting can be enabled via the `jit_trace` parameter.
* The history callback can be constructed via `t_clbk("history")` and needs to be passed during the *construction* of the learner.
* The validation and measures can be specified via `measures_valid` and take a measure object that is constructed via `msr()`.
</details>

::: {.content-visible when-meta=solutions}
**Solution**

```{r}
library(ggplot2)

mlp <- lrn("classif.mlp",
  neurons = c(100, 100),
  batch_size = 128,
  epochs = 200,
  predict_type = "prob",
  validate = 0.3,
  jit_trace = TRUE,
  callbacks = t_clbk("history"),
  measures_valid = msr("classif.logloss")
)

mlp$train(ilpd_num)
head(mlp$model$callbacks$history)
ggplot(mlp$model$callbacks$history) +
  geom_line(aes(x = epoch, y = valid.classif.logloss)) +
  labs(
    y = "Log-Loss (Validation)",
    x = "Epoch"
  ) +
  theme_minimal()
```
:::

**Question 2:** Early Stopping
Enable early stopping to prevent overfitting and re-train the learner (using a patience of 10). Print the final validation performance of the learner and the early stopped results. You can consult the [documentation of `LearnerTorch`](https://mlr3torch.mlr-org.com/reference/mlr_learners_torch.html) on how to access these two results (section *Active Bindings*).

<details>
<summary>Hint</summary>
You can enable early stopping by setting the `patience` parameter.
</details>

::: {.content-visible when-meta=solutions}
**Solution**

```{r}
mlp$configure(
  patience = 10
)
mlp$train(ilpd_num)
mlp$internal_tuned_values
mlp$internal_valid_scores
```
:::

**Question 3:** Early Stopping and Dropout Tuning

While early stopping in itself is already useful, `mlr3torch` also allows you to simultaneously tune the number of epochs using early stopping while tuning other hyperparameters via traditional hyperparameter tuning from `mlr3tuning`.

One thing we have not covered so far is that the MLP learner we have used so far also uses a dropout layer. The dropout probability can be configured via the `p` parameter.

Your task is to tune the dropout probability `p` in the range $[0, 1]$ and the epochs using early stopping (using the configuration from the previous exercise).

To adapt this to work with early stopping, you need to set the:

1. `epochs` to `to_tune(upper = <value>, internal = TRUE)`: This tells the `Tuner` that the learner will tune the number of epochs itself.
2. `$validate` field of the `"test"` so the same data is used for tuning and validation.
3. Tuning `measure` to `msr("internal_valid_score", minimize = TRUE)`. We set `minimize` to `TRUE` because we have used the log-loss as a validation measure.

Apart from this, the tuning works just like in tutorial 5. Use 3-fold cross-validation for the tuning and evaluate 10 configurations.

Run the tuning and print the optimal configuration.

::: {.content-visible when-meta=solutions}
**Solution**

```{r}
library(mlr3torch)

mlp$configure(
  epochs = to_tune(upper = 100, internal = TRUE),
  p = to_tune(lower = 0, upper = 1),
  validate = "test"
)

tuner <- tnr("random_search")
resampling <- rsmp("cv", folds = 3)
measure <- msr("internal_valid_score", minimize = TRUE)

ti <- tune(
  tuner = tuner,
  task = ilpd_num,
  learner = mlp,
  resampling = resampling,
  measure = measure,
  term_evals = 10
)

ti$learner_result_param_vals
```
:::
