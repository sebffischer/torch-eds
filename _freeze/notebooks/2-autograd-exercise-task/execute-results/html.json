{
  "hash": "90cd48c13482d377958006b9cea9a03e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Autograd\"\nsolutions: false\n---\n\n---\ntitle: \"Autograd\"\n---\n\n\n\n\n\n\n\n**Question 1**: Appreciating autograd\n\nConsider the following function:\n\n$$\nf(x) = x^2 + 3x + 2\n$$\n\nAs well as the function $g(x) = f(f(f(x)))$\n\nCalculate the gradient of both functions at point $x = 2$.\n\n::: {.content-visible when-meta=solutions}\n**Solution**\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(torch)\nx <- torch_tensor(2, requires_grad = TRUE)\nf <- function(x) {\n  x^2 + 3 * x + 2\n}\ng <- function(x) {\n  f(f(f(x)))\n}\n\n# Store the gradient, i.e., f'(2)\nf(x)$backward()\ngrad <- x$grad$clone()\ngrad\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntorch_tensor\n 7\n[ CPUFloatType{1} ]\n```\n\n\n:::\n\n```{.r .cell-code}\n# For another backward pass, we reset the gradient as they otherwise accumulate\nx$grad$zero_()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntorch_tensor\n 0\n[ CPUFloatType{1} ]\n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate the gradient of g(x)\ng(x)$backward()\n\n# Create a copy of the gradient\ngrad2 <- x$grad$clone()\ngrad2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntorch_tensor\n 69363\n[ CPUFloatType{1} ]\n```\n\n\n:::\n\n```{.r .cell-code}\n# Zero gradients for good measure\nx$grad$zero_()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntorch_tensor\n 0\n[ CPUFloatType{1} ]\n```\n\n\n:::\n:::\n\n\n:::\n\n**Question 2**: Approximating functions with gradients\n\nThe defining feature of the gradient is that it allows us to approximate the function locally by a linear function.\n\nI.e., for some value $x^*$, we know for very small $\\delta$, that\n\n$$\nf(x^* + \\delta) \\approx f(x^*) + f'(x^*) \\cdot \\delta\n$$\n\nPlot the function from earlier as well as the local linear approximation at $x = 2$ using `ggplot2`.\n\n1. Define a function `f_approx` that takes a value `delta` and returns the value of the function at `x^* + delta` using the linear approximation.\n2. Create a sequence with 100 equidistant values between -4 to 4 using `torch_linspace()`.\n3. Create a `data.frame` with columns `x`, `y_true`, `y_approx`.\n4. Use `ggplot2` to plot the function and its linear approximation.\n\n::: {.content-visible when-meta=solutions}\n**Solution**\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nx <- x$detach() # No need to track gradients anymore\ndeltas <- torch_linspace(-4, 4, 100)\ny_true <- f(x + deltas)\ny_approx <- f(x) + grad * deltas\n\nd <- data.frame(x = as_array(deltas), y_true = as_array(y_true), y_approx = as_array(y_approx))\n\nggplot(d, aes(x = x)) +\n  geom_line(aes(y = y_true, color = \"True function\")) +\n  geom_line(aes(y = y_approx, color = \"Linear approximation\")) +\n  theme_minimal() +\n  labs(\n    title = \"Gradient as a local linear approximation\",\n    y = \"f(x)\",\n    x = \"x\",\n    colour = \"\"\n  )\n```\n\n::: {.cell-output-display}\n![](2-autograd-exercise-task_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n:::\n\n**Question 3**: Look ma, I made my own autograd function\n\nIn this exercise, we will build our own, custom autograd function.\nWhile you might rarely need this in practice, it still allows you to get a better understanding of how the autograd system works.\nThere is also a tutorial on this on the `torch` [website](https://torch.mlverse.org/docs/articles/extending-autograd).\n\nTo construct our own autograd function, we need to define:\n\n1. The forward pass:\n   - How to calculate outputs from input\n   - What to save for the backward pass\n\n2. The backward pass:\n   - How to calculate the gradient of the output with respect to the input\n\nThe task is to re-create the ReLU activation function, which is a common activation function in neural networks and which is defined as:\n\n$$\n\\text{ReLU}(x) = \\max(0, x)\n$$\n\nNote that strictly speaking, the ReLU function is not differentiable at $x = 0$ (but a subgradient can be used instead).\nThe derivative/subgradient of the ReLU function is:\n\n$$\n\\text{ReLU}'(x) = \\begin{cases}\n1 & \\text{if } x > 0 \\\\\n0 & \\text{if } x \\leq 0 \\\\\n\\end{cases}\n$$\n\nIn `torch`, a custom autograd function can be constructed using `autograd_function()` function and it accepts arguments `forward` and `backward` which are functions that define the forward and backward pass:\nThey both take as first argument a `ctx`, which is a communication object that is used to save information during the forward pass to be able to compute the gradient in the backward pass.\nThe return value of the backward pass should be a list of gradients with respect to the inputs.\nTo check whether a gradient for an input is needed (has `requires_grad = TRUE`), you can use `ctx$needs_input_grad` which is a named list with boolean values for each input.\n\nThe backward function additionally takes a second argument `grad_output`, which is the gradient of the output:\nE.g., if our function is $f(x)$ and we calculate the gradient of $g(x) = h(f(x))$, then `grad_output` is the derivative of $g$ with respect to its input, evaluated at $f(x)$.\nThis is essentially the chain rule: $\\frac{\\partial g}{\\partial x} = \\frac{\\partial g}{\\partial f} \\cdot \\frac{\\partial f}{\\partial x}$.\n\nFill out the missing parts (`...`) in the code below.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrelu <- autograd_function(\n  forward = function(ctx, input) {\n    mask <- ...\n    output <- torch_where(mask, ...)\n    ctx$save_for_backward(mask)\n    output\n  },\n  backward = function(ctx, grad_output) {\n    grads <- list(input = NULL)\n    if (ctx$needs_input_grad$input) {\n      mask <- ctx$saved_variables[[1]]\n      grads$input <- ...\n    }\n    grads\n  }\n)\n```\n:::\n\n\n\nTo check that it's working, use the code below (with your `relu` instead of `nnf_relu`) and check that the results are the same.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx <- torch_tensor(-1, requires_grad = TRUE)\n(nnf_relu(x)^2)$backward()\nx$grad\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntorch_tensor\n 0\n[ CPUFloatType{1} ]\n```\n\n\n:::\n\n```{.r .cell-code}\nx$grad$zero_()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntorch_tensor\n 0\n[ CPUFloatType{1} ]\n```\n\n\n:::\n\n```{.r .cell-code}\nx <- torch_tensor(3, requires_grad = TRUE)\n(nnf_relu(x)^2)$backward()\nx$grad\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntorch_tensor\n 6\n[ CPUFloatType{1} ]\n```\n\n\n:::\n:::\n\n\n\n::: {.content-visible when-meta=solutions}\n**Solution**\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrelu <- autograd_function(\n  forward = function(ctx, input) {\n    mask <- input > 0\n    output <- torch_where(mask, input, torch_tensor(0))\n    ctx$save_for_backward(mask)\n    output\n  },\n  backward = function(ctx, grad_output) {\n    grads <- list(input = NULL)\n    if (ctx$needs_input_grad$input) {\n      mask <- ctx$saved_variables[[1]]\n      grads$input <- grad_output * mask\n    }\n    grads\n  }\n)\n\nx <- torch_tensor(-1, requires_grad = TRUE)\n(relu(x)^2)$backward()\nx$grad\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntorch_tensor\n 0\n[ CPUFloatType{1} ]\n```\n\n\n:::\n\n```{.r .cell-code}\nx$grad$zero_()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntorch_tensor\n 0\n[ CPUFloatType{1} ]\n```\n\n\n:::\n\n```{.r .cell-code}\nx <- torch_tensor(3, requires_grad = TRUE)\n(relu(x)^2)$backward()\nx$grad\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntorch_tensor\n 6\n[ CPUFloatType{1} ]\n```\n\n\n:::\n:::\n\n\n:::\n\n",
    "supporting": [
      "2-autograd-exercise-task_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}